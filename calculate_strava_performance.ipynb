{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Athlete Performance based on Strava History\n",
    "This notebook tests different approches to use the athlete's history to predict his performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Strava API user token\n",
    "Import the Client from the [stravalib library](https://github.com/hozn/stravalib/) and load your Access Token.\n",
    "\n",
    "You can find your personal token at https://www.strava.com/settings/api. Copy your token to a file named `STRAVA_TOKEN` in the home directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stravalib import unithelper\n",
    "from stravalib.client import Client as StravaClient\n",
    "\n",
    "strava_token = !cat STRAVA_TOKEN\n",
    "strava_client = StravaClient(access_token=strava_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Activities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import sys\n",
    "from termcolor import colored\n",
    "\n",
    "thirty_weeks = datetime.timedelta(weeks=30)\n",
    "\n",
    "args = {\n",
    "    # 'after': datetime.datetime.now() - thirty_weeks, # start date is after specified value (UTC). datetime.datetime or str or None\n",
    "    # 'before': datetime.datetime(year=2017, month=12, day=31), # start date is before specified value (UTC). datetime.datetime or str or None\n",
    "    # 'limit': 50,  # Maximum activites retrieved\n",
    "}\n",
    "\n",
    "activities = strava_client.get_activities(**args)\n",
    "\n",
    "manual_activities = [activity for activity in activities if activity.manual]\n",
    "activities = [activity for activity in activities if not activity.manual]\n",
    "\n",
    "message = \"%d Activities imported\\n\" % len(activities)\n",
    "sys.stdout.write(colored(message, attrs=['bold']))\n",
    "print(\"%d Manual activities excluded\" % len(manual_activities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Activities by Activity Type\n",
    "We create a dictionnary containing lists of activities by [activity type](https://strava.github.io/api/v3/activities/#activity-types-a-idtypesnbspa).\n",
    "\n",
    "\n",
    "### Basic Activity Types:\n",
    "- `Ride`\n",
    "- `Run`\n",
    "- `Swim`\n",
    "- `Hike`\n",
    "- `Walk`\n",
    "\n",
    "### More Exotic ones:\n",
    "`AlpineSki`, `BackcountrySki`, `Canoeing`, `Crossfit`, `EBikeRide`, `Elliptical`, `IceSkate`, `InlineSkate`, `Kayaking`, `Kitesurf`, `NordicSki`, `RockClimbing`, `RollerSki`, `Rowing`, `Snowboard`, `Snowshoe`, `StairStepper`, `StandUpPaddling`, `Surfing`, `VirtualRide`, `WeightTraining`, `Windsurf`, `Workout`, `Yoga`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "activities_by_type = {}\n",
    "\n",
    "for activity in activities: \n",
    "    if activity.type not in activities_by_type:\n",
    "        activities_by_type[activity.type] = []\n",
    "    \n",
    "    activities_by_type[activity.type].append(activity)\n",
    "\n",
    "for activity_type, activity_list in activities_by_type.items():\n",
    "    sys.stdout.write(\"- %s: %d \\n\" % (activity_type, len(activity_list)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Activities by Gear\n",
    "We choose the activity type and group the activities by gear used during the activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_gear = {}\n",
    "\n",
    "for activity in activities:\n",
    "    if activity.gear_id not in activities_by_gear:\n",
    "        activities_by_gear[activity.gear_id] = []\n",
    "\n",
    "    activities_by_gear[activity.gear_id].append(activity) \n",
    "\n",
    "gear_ids = list(activities_by_gear)\n",
    "\n",
    "for gear_id in gear_ids:\n",
    "    if gear_id is not None:\n",
    "        gear = strava_client.get_gear(gear_id)\n",
    "        activities_by_gear[gear.name] = activities_by_gear.pop(gear_id)\n",
    "\n",
    "for activity_gear, activity_list in activities_by_gear.items():\n",
    "    sys.stdout.write(\"- %s: %d \\n\" % (activity_gear, len(activity_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Activities by Workout Type\n",
    "We group the activities by workout type:\n",
    "- `default run`,\n",
    "- `race run`,\n",
    "- `long run`,\n",
    "- `workout run`,\n",
    "- `default ride`,\n",
    "- `race ride`,\n",
    "- `workout ride`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_by_workout_type = {}\n",
    "\n",
    "for activity in activities:\n",
    "\n",
    "    if activity.workout_type not in activities_by_workout_type:\n",
    "        activities_by_workout_type[activity.workout_type] = []\n",
    "\n",
    "    activities_by_workout_type[activity.workout_type].append(activity)\n",
    "\n",
    "# Rename workout type\n",
    "workout_types = {\n",
    "    '0': 'default run',\n",
    "    '1': 'race run',\n",
    "    '2': 'long run',\n",
    "    '3': 'workout run',\n",
    "    '10': 'default ride',\n",
    "    '11': 'race ride',\n",
    "    '12': 'workout ride',\n",
    "}\n",
    "\n",
    "for key, name in workout_types.items():\n",
    "    if key in activities_by_workout_type:\n",
    "        activities_by_workout_type[name] = activities_by_workout_type.pop(key)\n",
    "        \n",
    "for workout_type, activities in activities_by_workout_type.items():\n",
    "    sys.stdout.write(\"- %s: %d \\n\" % (workout_type, len(activities)))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Streams from activities\n",
    "We select the activities based on the groups created before and import the corresponding streams into an list of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_activities = []\n",
    "\n",
    "# Activity Type (Run, Ride, Swim, etc.)\n",
    "# filtered_activities = activities_by_type['Ride']\n",
    "\n",
    "# Workout Type (race, workout, long run, etc...)\n",
    "# filtered_activities = activities_by_workout_type['race run']\n",
    "\n",
    "# Gear\n",
    "# filtered_activities.extend(activities_by_gear[None])\n",
    "filtered_activities.extend(activities_by_gear['Salomon Speedcross 3'])\n",
    "\n",
    "# Filter more\n",
    "# filtered_activities = [activity for activity in filtered_activities if activity.type == 'Run']\n",
    "\n",
    "# filtered_activities = [activity for activity in filtered_activities if 1800 < unithelper.meters(activity.total_elevation_gain).num < 2000]\n",
    "\n",
    "\n",
    "observations = []\n",
    "stream_types = ['time', 'altitude', 'distance']\n",
    "\n",
    "for activity in filtered_activities:\n",
    "    raw_streams = strava_client.get_activity_streams(activity.id, types=stream_types, resolution='low')\n",
    "    if all(stream_type in raw_streams for stream_type in stream_types):\n",
    "        observations.append({'activity': activity, 'streams': raw_streams})\n",
    "        status = 'added'\n",
    "    else:\n",
    "        status = 'skipped'\n",
    "    \n",
    "    date = activity.start_date.strftime('%d.%m.%y')\n",
    "    activity_total_elevation = unithelper.meters(activity.total_elevation_gain)\n",
    "    activity_distance = unithelper.kilometers(activity.distance)\n",
    "    \n",
    "    message = \"%s: %s %s: %s - %s, %s+... \\n\" % (status, date, activity.type, activity.name, activity_distance, activity_total_elevation)\n",
    "    sys.stdout.write(message)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare DataFrame for Polynomial Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic assumption is that there is a polynomial relationship between the **pace** of the athlete and the **slope** of travelled terrain, plus **total elevation gain**:\n",
    "\n",
    "$$y = ax^2 + bx + ex + c $$\n",
    "\n",
    "\n",
    "Where:\n",
    "$$slope = x = \\frac{elevation\\:in\\:meters}{distance\\:in\\:meters}$$\n",
    "\n",
    "\n",
    "and:\n",
    "$$pace = y = \\frac{seconds}{meter}$$\n",
    "\n",
    "\n",
    "We try to fit the data with a polynomial regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for observation in observations:\n",
    "    data = pd.DataFrame()\n",
    "    result = pd.DataFrame()\n",
    "    for key, stream in observation['streams'].items():\n",
    "        data[key] = stream.data\n",
    "\n",
    "    result['gradient']  = data['altitude'].diff() / data['distance'].diff()\n",
    "    result['pace'] = data['time'].diff() / data['distance'].diff()\n",
    "    result['totalup'] = float(unithelper.kilometers(observation['activity'].total_elevation_gain))\n",
    "    result['length'] = float(unithelper.kilometers(observation['activity'].distance))\n",
    "\n",
    "    results = results.append(result[result.gradient.notnull()])\n",
    "    \n",
    "results = results.sort_values(['gradient'])\n",
    "results = results.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "**TODO**: Refactor with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = results[np.abs(results.pace -results.pace.mean())<=(2*results.pace.std())] #keep only the ones that are within +3 to -3 standard deviations in the column 'pace'.\n",
    "results = results[np.abs(results.gradient -results.gradient.mean())<=(6*results.gradient.std())] #keep only the ones that are within +6 to -6 standard deviations in the column 'gradient'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline                     \n",
    "\n",
    "results['gradient_squared'] = results.gradient**2\n",
    "variables = results[['gradient_squared', 'gradient', 'totalup']]\n",
    "                           \n",
    "target = results['pace']\n",
    "\n",
    "X = variables\n",
    "y = target\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X,y)\n",
    "\n",
    "gradient = variables['gradient']\n",
    "\n",
    "pace = target * 1000 / 60\n",
    "totalup = variables['totalup']\n",
    "predictions = model.predict(X) * 1000 / 60\n",
    "\n",
    "print('Based on %d entries.' % variables.shape[0])\n",
    "print('R-squared: %s' % model.score(X,y))\n",
    "print('Intercept: %s' % model.intercept_)\n",
    "print('Coef: %s' % model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "\n",
    "# 3d plot\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.view_init(10, -45)\n",
    "ax.plot(gradient, totalup, pace, 'b.')\n",
    "ax.plot(gradient, totalup, predictions, 'r.')\n",
    "\n",
    "# 2d plot\n",
    "ax = fig.add_subplot(122)\n",
    "ax.plot(gradient, pace, 'b,')\n",
    "ax.plot(gradient, predictions, 'r.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Flat Pace and Maximum Speed with Total Elevation Gain\n",
    "\n",
    "**TODO**: explain formula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_up_mean = totalup.mean()\n",
    "# length_mean = length.mean()\n",
    "\n",
    "flat_param = model.intercept_\n",
    "slope_squared_param, slope_param, totalup_param = model.coef_\n",
    "flat_pace = (flat_param + totalup_param * total_up_mean ) * 1000 / 60\n",
    "\n",
    "\n",
    "# flat and max pace and speed\n",
    "print('flat pace:  %02d:%02d min/km' % (math.floor(flat_pace), int(round(flat_pace % 1 * 60, 0))))\n",
    "print('flat speed: %.2f km/h' % (1/flat_pace * 60))\n",
    "min_x = -slope_param / (2 * slope_squared_param)\n",
    "max_speed = (slope_squared_param * min_x**2 + slope_param * min_x + flat_param + totalup_param * total_up_mean) * 1000 / 60\n",
    "print('max pace:   %02d:%02d min/km at %06.2f percent slope' % (math.floor(max_speed), int(round(max_speed % 1 * 60, 0)), min_x * 100))\n",
    "print('max speed:  %.2f km/h at %06.2f percent slope' % (1/max_speed * 60, min_x * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Max Vertical Speed\n",
    "\n",
    "**TODO**: explain formula\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gain = 100\n",
    "distance = np.arange(gain, gain*10)\n",
    "seconds = (((slope_squared_param * (gain**2))/distance) + slope_param * gain + flat_param * distance + totalup_param * gain)/60 \n",
    "\n",
    "min_distance = ((slope_squared_param * gain**2)/flat_param)**(1/2)\n",
    "min_seconds = (((slope_squared_param * (gain**2))/min_distance) + slope_param * gain + flat_param * min_distance + totalup_param * gain)/60\n",
    "\n",
    "print('%d meters elevation gain in %.0f minutes and %d meters distance' % (gain, min_seconds, min_distance))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.plot(distance,seconds,'r-')\n",
    "ax.plot(min_distance, min_seconds,'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('route_data.json', orient='records')\n",
    "totalup = data.iloc[-1,-1]\n",
    "length = data.iloc[-1,2]\n",
    "\n",
    "data['distance'] = data['length'].diff()\n",
    "data = data[data['distance'] > 0]\n",
    "data['gradient'] = data['altitude'].diff() / data['distance']\n",
    "data['gradient_squared'] = data['gradient']**2\n",
    "\n",
    "route_variables = data.loc[2:, ['gradient_squared', 'gradient']]\n",
    "route_variables['totalup'] = totalup / 1000\n",
    "route_variables['length'] = length / 1000\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm.coef_ = model.coef_\n",
    "lm.intercept_ = model.intercept_\n",
    "\n",
    "route_variables['pace'] = lm.predict(route_variables)\n",
    "route_variables['time'] = \n",
    "\n",
    "\n",
    "print('%s: %s' % (totalup, length))\n",
    "\n",
    "route_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
